{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import save_model, load_model\n",
        "\n",
        "import string\n",
        "\n",
        "from pathlib import Path\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "MUQsT9Pfcfej"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Steps involved in RNN modeling\n",
        "\n",
        "1. preprocessing\n",
        "2. training\n",
        "3. post-processing\n",
        "\n",
        "* **Pre-processing**\n",
        "\n",
        "  * This step involves converting\n",
        "      * the raw game state and guessed letters into a format that can be fed into the model.\n",
        "  * For example,\n",
        "  * Game state can be represented as\n",
        "      * a sequence of integers, where each integer corresponds to a letter of the alphabet\n",
        "      * (with a special value for unknown letters).\n",
        "  * The guessed letters could be\n",
        "      * represented as a binary vector,\n",
        "      * where each element indicates whether a particular letter has been guessed.\n",
        "\n",
        "\n",
        "\n",
        "*  **Training**\n",
        "\n",
        " * Training involves\n",
        "     * feeding the preprocessed data into the model and\n",
        "     * adjusting the model’s parameters based on its predictions.\n",
        " * The goal is to\n",
        "     * minimize the difference between the model’s predictions and the actual outcomes.\n",
        " * This is typically done using a variant of stochastic gradient descent.\n",
        " * You would need a large dataset of words to train the model.\n",
        " * The loss function could be the\n",
        "     * cross-entropy loss between the model’s predictions and the actual next letters."
      ],
      "metadata": {
        "id": "SkWS8sRreRf5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NN Architecture\n",
        "\n",
        " 1. state embedding - currenyt state of the game\n",
        " 2. guessed word embedding\n",
        " 3. Model - combine above two embeddings and dense layers"
      ],
      "metadata": {
        "id": "g5yJRsgwesqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_state_embedding(maxlen = 29):\n",
        "    inp = tf.keras.layers.Input(shape=(maxlen,))\n",
        "    x = tf.keras.layers.Embedding(30, 100, mask_zero = True)(inp)\n",
        "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100, dropout=0.3, return_sequences=True))(x)\n",
        "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100, dropout=0.2, return_sequences=True))(x)\n",
        "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "\n",
        "    return(tf.keras.models.Model(inp, x, name='StateEmbedding'))\n",
        "\n",
        "\n",
        "def generate_guessed_embedding():\n",
        "    inp = tf.keras.layers.Input(shape=(26))\n",
        "    x = tf.keras.layers.Dense(256, activation='relu')(inp)\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "    return(tf.keras.models.Model(inp, x, name='GuessedEmbedding'))\n",
        "\n",
        "\n",
        "def generate_action_network(maxlen=29):\n",
        "    state_embedding = generate_state_embedding(maxlen=maxlen)\n",
        "    guessed_embedding = generate_guessed_embedding()\n",
        "    x = tf.keras.layers.Concatenate()([state_embedding.output, guessed_embedding.output])\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dense(26, activation='softmax')(x)\n",
        "    final_model = tf.keras.models.Model([state_embedding.input, guessed_embedding.input], x, name='action_network')\n",
        "    final_model.compile(loss = 'categorical_crossentropy', optimizer= tf.keras.optimizers.Nadam(1e-3, clipnorm=1))\n",
        "    return final_model\n",
        "\n",
        "rnn_model = generate_action_network()\n",
        "rnn_model.summary()\n"
      ],
      "metadata": {
        "id": "nl_EEjvjcjhM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdaee3ae-aea4-418e-b862-8d50abf819a5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"action_network\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 29)]                 0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 29, 100)              3000      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " bidirectional (Bidirection  (None, 29, 200)              160800    ['embedding[0][0]']           \n",
            " al)                                                                                              \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirecti  (None, 29, 200)              240800    ['bidirectional[0][0]']       \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 26)]                 0         []                            \n",
            "                                                                                                  \n",
            " global_average_pooling1d (  (None, 200)                  0         ['bidirectional_1[0][0]']     \n",
            " GlobalAveragePooling1D)                                                                          \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 256)                  6912      ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  25728     ['global_average_pooling1d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 128)                  32896     ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 64)                   8256      ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 64)                   8256      ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 128)                  0         ['dense_1[0][0]',             \n",
            "                                                                     'dense_4[0][0]']             \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 128)                  16512     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 64)                   8256      ['dense_5[0][0]']             \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 26)                   1690      ['dense_6[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 513106 (1.96 MB)\n",
            "Trainable params: 513106 (1.96 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_state(eps_states, inference=False):\n",
        "    '''\n",
        "    This function is used to convert a list of strings (`eps_states`) into a numerical representation using a ascii encoding scheme\n",
        "    Parameters:\n",
        "      * eps_states: list of strings (game state) that need to be encoded\n",
        "      * inference` (optional): Boolean flag - treats `eps_states` as a single string rather than a list of strings.\n",
        "    '''\n",
        "    if inference == True:\n",
        "        eps_states = [eps_states]\n",
        "\n",
        "    # Array init\n",
        "    eps_state_int = []\n",
        "    for i in range(len(eps_states)):\n",
        "        eps_state_int.append([ord(c) - ord('a') + 1  if c != '_' else 27 for c in eps_states[i]])\n",
        "\n",
        "    # max number of letters in the vocab\n",
        "    word_len = 29\n",
        "    eps_steps_count = len(eps_state_int)\n",
        "\n",
        "    # filling the array\n",
        "    # padding of 0\n",
        "    eps_state_int_np = np.zeros((eps_steps_count, word_len))\n",
        "    for eps_inx, eps_step_list in enumerate(eps_state_int):\n",
        "        eps_state_int_np[eps_inx, :len(eps_step_list)] = eps_step_list\n",
        "\n",
        "    return eps_state_int_np\n"
      ],
      "metadata": {
        "id": "328uEinzcqt_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `encode_guess` function is used to convert a list of guessed letters (`eps_guessed_letters`) into a binary numerical representation. Here's a step-by-step explanation:\n",
        "\n",
        "1. **Input**: The function takes two arguments:\n",
        "   - `eps_guessed_letters`: A list of strings where each string represents a set of guessed letters.\n",
        "   - `inference` (optional): A boolean flag that defaults to `False`. If it's `True`, the function treats `eps_guessed_letters` as a single string rather than a list of strings.\n",
        "\n",
        "2. **Encoding Scheme**: Each character in the string is converted to an integer. The conversion is based on the position of the character in the English alphabet (i.e., 'a' is 0, 'b' is 1, ..., 'z' is 25). The underscore character ('_') is treated specially and is assigned the number 26.\n",
        "\n",
        "3. **Array Initialization**: An empty numpy array `eps_guessed_int` of shape `(len(eps_guessed_letters), num_letters)` is initialized with zeros, where `num_letters` is the number of letters in the English alphabet (26).\n",
        "\n",
        "4. **Filling the Array**: The encoded integers are then used to fill the `eps_guessed_int` array. Each row of the array corresponds to one string from `eps_guessed_letters`. For each guessed letter in a string, the corresponding position in the array is set to 1.\n",
        "\n",
        "5. **Output**: The function returns the numpy array `eps_guessed_int` containing the binary encoded representation of `eps_guessed_letters`.\n",
        "\n",
        "This function could be used in various applications such as natural language processing or machine learning where textual data needs to be converted into a numerical format that can be processed by algorithms. It's important to note that the specific encoding scheme used here (i.e., 'a' to 0, 'b' to 1, etc.) is just one of many possible ways to encode textual data. The best encoding scheme to use can depend on the specific requirements of the application."
      ],
      "metadata": {
        "id": "Wm-K1Z34l01I"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dSHalRcGl0m6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_guess(eps_guessed_letters, inference=False):\n",
        "    '''\n",
        "    Function is used to convert a list of guessed letters (`eps_guessed_letters`) into a binary numerical representation.\n",
        "    Encoding scheme: 'abz' : [1, 1, 0, 0, 0, ..... 0, 1]\n",
        "    At start of game, encoded vector = zeros(26)\n",
        "    Parameters:\n",
        "    * eps_guessed_letters: A list of strings where each string represents a set of guessed letters.\n",
        "    * inference` (optional): Boolean flag - treats `eps_states` as a single string rather than a list of strings.\n",
        "    '''\n",
        "    if inference == True:\n",
        "        eps_guessed_letters = [eps_guessed_letters]\n",
        "\n",
        "    num_letters = 26\n",
        "    eps_guessed_int = np.zeros((len(eps_guessed_letters), num_letters))\n",
        "\n",
        "    for eps_inx, eps_guess_list in enumerate(eps_guessed_letters):\n",
        "        eps_guess_list = [ord(c) - ord('a') if c != '_' else 26 for c in eps_guess_list]\n",
        "        eps_guessed_int[eps_inx, eps_guess_list] = 1\n",
        "\n",
        "    return eps_guessed_int"
      ],
      "metadata": {
        "id": "ejK8ont7fBcR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F0oq-mPtfFcv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict and play hangman game\n",
        "\n",
        " 1. Generate raw state from hangman\n",
        " 2. Initiate guessed word list\n",
        " 3. encode the state and guessed_letters to format suitable for NN\n",
        " 4. Generate prediction\n",
        " 5. Decode the prediction\n",
        " 6. Feed it to hangman and get next state"
      ],
      "metadata": {
        "id": "xa5C6AOrfGGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "current_working_dir = Path('.')\n",
        "current_working_dir.absolute()\n",
        "\n",
        "with open(current_working_dir.absolute() / 'words_250000_train.txt') as file:\n",
        "    content = file.read()\n",
        "    words = content.split()\n",
        "\n",
        "data_letters = \"\".join(words)\n",
        "len(words), words[:5], len(data_letters), data_letters[:20],\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oveLI_6-fRdZ",
        "outputId": "47ce8137-a47d-4726-b17f-02ddca94229f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(227300,\n",
              " ['aaa', 'aaaaaa', 'aaas', 'aachen', 'aaee'],\n",
              " 2124746,\n",
              " 'aaaaaaaaaaaasaachena')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_letters = Counter(data_letters)\n",
        "len(count_letters.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7dqZT0bfT9i",
        "outputId": "43fd5621-8a5c-4549-c08e-3c48843943ed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ascii_letters = list(string.ascii_lowercase)\n",
        "ascii_letters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HckSMveFfZ2n",
        "outputId": "932b4c0e-7e76-4b50-d901-8641a5d3ea2d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_prediction(rnn_model, current_state, guessed_letters, policy='greedy'):\n",
        "    '''\n",
        "    Function is used to make a prediction based on the current state and the letters that have been guessed so far.\n",
        "    Parameters:\n",
        "    * rnn_model: The trained RNN model used for making predictions.\n",
        "    * current_state: The current state of the game\n",
        "    * guessed_letters: list of letters already guessed.\n",
        "    * policy (optional): The policy used for making predictions.\n",
        "      * Defaults : 'greedy' - choose the letter with highest output\n",
        "      * If 'stochastic': random choice based on the probabilities output by the model.\n",
        "\n",
        "    '''\n",
        "\n",
        "    current_state = \"\".join(current_state)\n",
        "\n",
        "    # encode\n",
        "    eps_state_int = encode_state(current_state, inference=True)\n",
        "    eps_guessed_int = encode_guess(guessed_letters, inference=True)\n",
        "\n",
        "    probs = rnn_model([eps_state_int, eps_guessed_int])\n",
        "    probs = probs.numpy().squeeze()\n",
        "    probs /= probs.sum()\n",
        "\n",
        "    if policy == 'greedy':\n",
        "        i = 1\n",
        "        sorted_probs = probs.argsort()\n",
        "        # if predict letter already used\n",
        "        while ascii_letters[sorted_probs[-i]] in guessed_letters:\n",
        "            i += 1\n",
        "        idx_act = sorted_probs[-i]\n",
        "    elif policy == 'stochastic':\n",
        "        idx_act = np.random.choice(np.arange(probs.shape[0]), p=probs)\n",
        "        while ascii_letters[idx_act] in guessed_letters:\n",
        "            idx_act = np.random.choice(np.arange(probs.shape[0]), p=probs)\n",
        "\n",
        "    # extarct the letter for represented number encoding\n",
        "    guess_char = ascii_letters[idx_act]\n",
        "\n",
        "    return guess_char\n",
        "\n"
      ],
      "metadata": {
        "id": "cbj4YtwMcqq8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import random\n",
        "\n",
        "def hangman_game(random_word, rnn_model, display=False):\n",
        "\n",
        "    state = ['_' for _ in random_word]\n",
        "    guessed_letters = []\n",
        "    attempts = len(random_word)\n",
        "\n",
        "    if display == True:\n",
        "        print('TRUE WORD:', random_word)\n",
        "\n",
        "    eps_states = [state.copy()]\n",
        "    eps_guessed_letters = [guessed_letters.copy()]\n",
        "\n",
        "    while (attempts > 0) and not (set(random_word) <= set(state)):\n",
        "        if display == True:\n",
        "            print('\\t \\n' + ' '.join(state))\n",
        "        guess = model_prediction(rnn_model, state, guessed_letters, policy='greedy')\n",
        "\n",
        "        if display == True:\n",
        "            print(f'Current state: {state}, \\t Prediction: {guess}, \\t Guesssed :{guessed_letters}')\n",
        "        if (guess in random_word) and (guess not in guessed_letters):\n",
        "            for i in range(len(random_word)):\n",
        "                if random_word[i] == guess:\n",
        "                    state[i] = guess\n",
        "        else:\n",
        "            attempts -= 1\n",
        "            if display == True:\n",
        "                print(f\"\\t That letter - '{guess}' doesn't appear in the word; Attempts left: {attempts}\")\n",
        "\n",
        "        guessed_letters.append(guess)\n",
        "        eps_states.append(state.copy())\n",
        "        eps_guessed_letters.append(guessed_letters.copy())\n",
        "\n",
        "        if '_' not in state:\n",
        "            if display == True:\n",
        "                print(f\"You guessed the word! \\n You survived! \\n Word was: {random_word}\")\n",
        "            return True, eps_states, eps_guessed_letters, random_word\n",
        "    else:\n",
        "        if display == True:\n",
        "            print(f\"You lost! \\nWord was: {random_word}\")\n",
        "        return False, eps_states, eps_guessed_letters, random_word\n",
        "\n",
        "random_word = 'ascaridiasis' # 'zebra'\n",
        "result = hangman_game(random_word, rnn_model)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhW0Yq63cqEZ",
        "outputId": "0b0b8545-cb1c-437e-cb50-7035ecd45254"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(False, [['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', 'c', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', 'c', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', 'c', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', 'c', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', 'c', '_', '_', 'i', '_', 'i', '_', '_', 'i', '_'], ['_', '_', 'c', '_', '_', 'i', '_', 'i', '_', '_', 'i', '_'], ['_', '_', 'c', '_', 'r', 'i', '_', 'i', '_', '_', 'i', '_'], ['_', '_', 'c', '_', 'r', 'i', '_', 'i', '_', '_', 'i', '_'], ['_', '_', 'c', '_', 'r', 'i', '_', 'i', '_', '_', 'i', '_'], ['_', '_', 'c', '_', 'r', 'i', '_', 'i', '_', '_', 'i', '_'], ['_', '_', 'c', '_', 'r', 'i', 'd', 'i', '_', '_', 'i', '_'], ['_', 's', 'c', '_', 'r', 'i', 'd', 'i', '_', 's', 'i', 's'], ['_', 's', 'c', '_', 'r', 'i', 'd', 'i', '_', 's', 'i', 's'], ['_', 's', 'c', '_', 'r', 'i', 'd', 'i', '_', 's', 'i', 's'], ['_', 's', 'c', '_', 'r', 'i', 'd', 'i', '_', 's', 'i', 's']], [[], ['p'], ['p', 'n'], ['p', 'n', 'c'], ['p', 'n', 'c', 'h'], ['p', 'n', 'c', 'h', 'q'], ['p', 'n', 'c', 'h', 'q', 'f'], ['p', 'n', 'c', 'h', 'q', 'f', 'i'], ['p', 'n', 'c', 'h', 'q', 'f', 'i', 'l'], ['p', 'n', 'c', 'h', 'q', 'f', 'i', 'l', 'r'], ['p', 'n', 'c', 'h', 'q', 'f', 'i', 'l', 'r', 'j'], ['p', 'n', 'c', 'h', 'q', 'f', 'i', 'l', 'r', 'j', 'g'], ['p', 'n', 'c', 'h', 'q', 'f', 'i', 'l', 'r', 'j', 'g', 'y'], ['p', 'n', 'c', 'h', 'q', 'f', 'i', 'l', 'r', 'j', 'g', 'y', 'd'], ['p', 'n', 'c', 'h', 'q', 'f', 'i', 'l', 'r', 'j', 'g', 'y', 'd', 's'], ['p', 'n', 'c', 'h', 'q', 'f', 'i', 'l', 'r', 'j', 'g', 'y', 'd', 's', 'w'], ['p', 'n', 'c', 'h', 'q', 'f', 'i', 'l', 'r', 'j', 'g', 'y', 'd', 's', 'w', 'k'], ['p', 'n', 'c', 'h', 'q', 'f', 'i', 'l', 'r', 'j', 'g', 'y', 'd', 's', 'w', 'k', 'o']], 'ascaridiasis')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def prepare_training_data(eps_states, eps_guessed_letters, answer):\n",
        "    '''\n",
        "    Function prepares the training data for a RNN model that is learning to play hangman\n",
        "    Parameters:\n",
        "    * eps_states: The states of the game at each step.\n",
        "    * eps_guessed_letters: The letters that have been guessed at each step.\n",
        "    * answer: The correct word that is being guessed.\n",
        "\n",
        "    '''\n",
        "\n",
        "    # encode in proper format\n",
        "    eps_state_int = encode_state(eps_states)\n",
        "    eps_guessed_int = encode_guess(eps_guessed_letters)\n",
        "\n",
        "    # Target - SL\n",
        "    # correct action = choose unused letter + exist in the word\n",
        "\n",
        "    # Target - predict the correct letter which is not already guessed\n",
        "    correct_vector = [1 if l in answer else 0 for l in ascii_letters]\n",
        "    target = correct_vector * (1-eps_guessed_int)\n",
        "    norm_ = target.sum(axis=1)\n",
        "\n",
        "    # Remove the last state of succesful prediction cases\n",
        "    if np.isclose(norm_, 0.0).any():\n",
        "        if np.isclose(norm_, 0.0).sum() > 1:\n",
        "            print('target:', target)\n",
        "            print('norm:', norm_)\n",
        "            print('eps_guessed_letters', eps_guessed_letters[-1])\n",
        "            print('eps_states', eps_states[-1])\n",
        "            print('answer', answer)\n",
        "            raise()\n",
        "        else:\n",
        "\n",
        "            eps_state_int = eps_state_int[:-1,:]\n",
        "            eps_guessed_int = eps_guessed_int[:-1,:]\n",
        "            target = target[:-1,:]\n",
        "            norm_ = target.sum(axis=1)\n",
        "\n",
        "    target /= norm_.reshape(-1, 1)\n",
        "\n",
        "    # Target - RL\n",
        "    # if action_letter part of answer = 1 else 0\n",
        "    # target = np.array(answer)\n",
        "\n",
        "    return(eps_state_int, eps_guessed_int, target)\n"
      ],
      "metadata": {
        "id": "8i-2UYnrdE-x"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import logging\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "logging.basicConfig(filename= current_working_dir.absolute() / 'rnn_embedding.log', level=logging.INFO, filemode='w')\n",
        "logging.info(f\" \\n \\nRNN w/ embedding\")\n"
      ],
      "metadata": {
        "id": "I4eckfFndGlh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "buffer_states_data = None\n",
        "buffer_guessed_letters = None\n",
        "buffer_target = None\n",
        "results = []\n",
        "losses = []\n",
        "callabck_freq = 50\n",
        "epochs = 2500\n",
        "batch_size = 300\n",
        "buffer_size = 2000\n",
        "wins_in_epoch = 0\n",
        "training_iters = 3\n",
        "patience = 5\n",
        "patience_counter = 0\n",
        "best_loss = np.inf\n",
        "\n",
        "rnn_model = generate_action_network()\n",
        "start_time = time.time()\n",
        "\n",
        "for eps in range(1, epochs):\n",
        "\n",
        "    # word for the game\n",
        "    random_word = random.choice(words)\n",
        "    logging.info(f\"\\n Episode: {eps}, Random word: {random_word}\")\n",
        "\n",
        "    # play the game\n",
        "    result, eps_states, eps_guessed_letters, answer = hangman_game(random_word, rnn_model)\n",
        "    # encode the episode data\n",
        "    eps_state_int, eps_guessed_int, target = prepare_training_data(eps_states, eps_guessed_letters, answer)\n",
        "\n",
        "    eps_len = eps_state_int.shape[0]\n",
        "    logging.info(f\"eps len: {eps_len}\")\n",
        "    logging.info(eps_guessed_letters[-1])\n",
        "\n",
        "    # fill the data in buffer\n",
        "    if eps == 1:\n",
        "        buffer_states_data, buffer_guessed_letters, buffer_target = eps_state_int, eps_guessed_int, target\n",
        "        print(eps, buffer_states_data.shape, buffer_guessed_letters.shape, buffer_target.shape)\n",
        "    else:\n",
        "        if buffer_states_data.shape[0] > buffer_size:\n",
        "            start_inx = eps_len\n",
        "        else:\n",
        "            start_inx = 0\n",
        "\n",
        "        buffer_states_data = np.vstack([buffer_states_data[start_inx:, :], eps_state_int])\n",
        "        buffer_guessed_letters = np.vstack([buffer_guessed_letters[start_inx:, :], eps_guessed_int])\n",
        "        buffer_target = np.vstack([buffer_target[start_inx:, :], target])\n",
        "\n",
        "        assert np.array_equal(buffer_states_data[-1, :], eps_state_int[-1, :])\n",
        "\n",
        "    if buffer_states_data.shape[0] > (batch_size + eps_len + 1):\n",
        "        idx = np.random.choice(buffer_states_data.shape[0] - eps_len, batch_size, replace=False)\n",
        "    else:\n",
        "        idx = np.arange(buffer_states_data.shape[0] - eps_len)\n",
        "\n",
        "    # sample data from buffer for training and testing\n",
        "    tt_states_data = np.vstack([buffer_states_data[idx, :], eps_state_int])\n",
        "    tt_guessed_letters = np.vstack([buffer_guessed_letters[idx, :], eps_guessed_int])\n",
        "    tt_target = np.vstack([buffer_target[idx, :], target])\n",
        "\n",
        "    inx_range = np.arange(tt_states_data.shape[0])\n",
        "    train_inx, test_inx = train_test_split(inx_range, test_size=0.2, random_state=42)\n",
        "\n",
        "    # train and test samples\n",
        "    train_states_data, test_states_data = tt_states_data[train_inx, :], tt_states_data[test_inx, :]\n",
        "    train_guessed_letters, test_guessed_letters = tt_guessed_letters[train_inx, :], tt_guessed_letters[test_inx, :]\n",
        "    train_target, test_target = tt_target[train_inx, :], tt_target[test_inx, :]\n",
        "\n",
        "    # train the model\n",
        "    for _ in range(training_iters):\n",
        "        loss = rnn_model.train_on_batch([train_states_data, train_guessed_letters], train_target)\n",
        "\n",
        "    val_loss = rnn_model.evaluate([test_states_data, test_guessed_letters], test_target, verbose=0)\n",
        "\n",
        "    results.append(result)\n",
        "    losses.append(val_loss)\n",
        "    wins_in_epoch += result\n",
        "    if eps % callabck_freq == 0:\n",
        "\n",
        "        avg_val_loss = sum(losses)/len(losses)\n",
        "        min_val_loss = min(losses)\n",
        "\n",
        "        if avg_val_loss < best_loss:\n",
        "            best_loss = min_val_loss\n",
        "            patience_counter = 0\n",
        "            save_model(rnn_model, current_working_dir.absolute() / 'rnn_model_current_best.h5')\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "        if patience_counter > patience:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "\n",
        "        print(f\"Episode: {eps}, Loss: {avg_val_loss:.2f}, #WINS (in last {callabck_freq} eps): {wins_in_epoch}, \\\n",
        "              Time taken: {time.time() - start_time:.2f} secs\")\n",
        "        print('\\t', eps_guessed_letters[-1])\n",
        "        logging.info(f\"Loss: {avg_val_loss:.2f}, \\\n",
        "                     #WINS (in last {callabck_freq} eps): {wins_in_epoch}, \\\n",
        "                     \\Time taken: {time.time() - start_time:.2f} secs\"\n",
        "                    )\n",
        "\n",
        "\n",
        "        losses = []\n",
        "        wins_in_epoch = 0\n",
        "        start_time = time.time()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrCkWIJZdIwO",
        "outputId": "6dd51c3a-c579-4d6d-a6cc-8784935c3ccd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (11, 29) (11, 26) (11, 26)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-42133de924bb>:85: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  save_model(rnn_model, current_working_dir.absolute() / 'rnn_model_current_best.h5')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 50, Loss: 2.25, #WINS (in last 50 eps): 21,               Time taken: 96.91 secs\n",
            "\t ['s', 'h', 'r', 'e', 't', 'n', 'p', 'u', 'd', 'c', 'b', 'a', 'o', 'l', 'm', 'i', 'k', 'x', 'w', 'g', 'z', 'f', 'y', 'v']\n",
            "Episode: 100, Loss: 2.04, #WINS (in last 50 eps): 10,               Time taken: 51.41 secs\n",
            "\t ['e', 'r', 'i', 's', 'n', 'a', 'l', 't', 'u', 'h', 'm', 'o', 'p', 'g', 'w', 'd', 'c', 'y']\n",
            "Episode: 150, Loss: 2.00, #WINS (in last 50 eps): 20,               Time taken: 44.20 secs\n",
            "\t ['r', 's', 'w', 'i', 'o', 'd', 'e']\n",
            "Episode: 200, Loss: 1.93, #WINS (in last 50 eps): 11,               Time taken: 40.41 secs\n",
            "\t ['e', 'f', 's', 't', 'w', 'k', 'u', 'i', 'n', 'o']\n",
            "Episode: 250, Loss: 1.86, #WINS (in last 50 eps): 18,               Time taken: 41.81 secs\n",
            "\t ['i', 'o', 'e', 't', 'u', 'a', 's', 'b', 'h', 'f', 'c', 'r', 'l', 'm', 'y', 'd', 'p', 'n']\n",
            "Episode: 300, Loss: 1.84, #WINS (in last 50 eps): 15,               Time taken: 42.88 secs\n",
            "\t ['e', 'a', 's', 'm', 'i', 'h', 'u', 'r', 't']\n",
            "Episode: 350, Loss: 1.80, #WINS (in last 50 eps): 21,               Time taken: 40.85 secs\n",
            "\t ['t', 'c', 'n', 'a', 'b', 'h', 's', 'l', 'm', 'u', 'p', 'r', 'o', 'd', 'g', 'i', 'e']\n",
            "Episode: 400, Loss: 1.77, #WINS (in last 50 eps): 20,               Time taken: 42.30 secs\n",
            "\t ['e', 'a', 'l', 'p', 'u', 'r', 't', 'g', 'i', 'd', 's', 'o', 'm', 'n']\n",
            "Episode: 450, Loss: 1.71, #WINS (in last 50 eps): 19,               Time taken: 39.96 secs\n",
            "\t ['r', 'a', 'd', 'n', 's', 'i', 'o', 'e', 't', 'f', 'c', 'w', 'h', 'l', 'u', 'g']\n",
            "Episode: 500, Loss: 1.72, #WINS (in last 50 eps): 26,               Time taken: 43.03 secs\n",
            "\t ['e', 'o', 'a', 'p', 'l', 'c', 'g', 't', 'i', 's', 'h', 'r', 'd', 'y', 'v', 'n', 'b', 'u']\n",
            "Episode: 550, Loss: 1.72, #WINS (in last 50 eps): 18,               Time taken: 40.59 secs\n",
            "\t ['t', 'e', 'a', 'o', 'y', 'l', 'p', 'r', 'h', 'i', 'n', 'c', 's', 'g', 'd', 'u']\n",
            "Episode: 600, Loss: 1.66, #WINS (in last 50 eps): 17,               Time taken: 41.47 secs\n",
            "\t ['e', 'r', 's', 'h', 'm', 'b', 'o', 'a', 'u', 'd', 'i', 'p', 'g']\n",
            "Early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and testing the model"
      ],
      "metadata": {
        "id": "V394pgbffy0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(rnn_model, current_working_dir.absolute() / 'rnn_model.h5')"
      ],
      "metadata": {
        "id": "YU7e-9KFdK1A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b11ff63-cfd2-4093-b733-d849f02d2938"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-8d2baedb2f3e>:1: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  save_model(rnn_model, current_working_dir.absolute() / 'rnn_model.h5')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# del rnn_model\n"
      ],
      "metadata": {
        "id": "jNTjnTkqdMG-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = load_model(current_working_dir.absolute() / 'rnn_model.h5')\n"
      ],
      "metadata": {
        "id": "a8knZD7hdNim"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for i in range(1, 10):\n",
        "    random_word = random.choice(words)\n",
        "\n",
        "    result, eps_states, eps_guessed_letters, answer = hangman_game(random_word, loaded_model, display=False)\n",
        "\n",
        "    count += result\n",
        "    print(f'Eps: {i}, WIN: {count}, %WIN: {(count / i)*100:.2f}')"
      ],
      "metadata": {
        "id": "l6tkU7QFdPXX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "291217b0-2d99-4c7a-acf0-2fd1c91d9d80"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eps: 1, WIN: 1, %WIN: 100.00\n",
            "Eps: 2, WIN: 1, %WIN: 50.00\n",
            "Eps: 3, WIN: 1, %WIN: 33.33\n",
            "Eps: 4, WIN: 1, %WIN: 25.00\n",
            "Eps: 5, WIN: 2, %WIN: 40.00\n",
            "Eps: 6, WIN: 2, %WIN: 33.33\n",
            "Eps: 7, WIN: 3, %WIN: 42.86\n",
            "Eps: 8, WIN: 4, %WIN: 50.00\n",
            "Eps: 9, WIN: 5, %WIN: 55.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7iZIe6qN5pri"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}